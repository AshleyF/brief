# 01 JAN 2021 Lexical Scoping

We left last year trying to think of how to handle situations like this:

```brief
let 'fry [flatmap [if [fry.fill] [fry.deepfry] fry.hole?]]
    let 'fry.fill [unless [quote] list? dup rot drop]
    let 'fry.deepfry [if [quote rot 2dip [fry] -rot] [quote] list? dup]
    let 'fry.hole? [= >sym '_ dup]
```

A word defined in terms of "child" words that aren't meant to be generally useful. This idea of prefixing with `fry.` isn't satisfactory.

An interesting thing to notice is that `let` expressions can actually be used _within_ word definitions. In fact, an interesting idea is to use "dangling `lets`" to name values from the stack:

```brief
let 'pyth [sqrt + * a a * b b let 'b let 'a]
```

That's a nice, direct mapping from the mathematical expression. Perhaps not as simple as `let 'pyth [sqrt + sq swap sq]` in this case, but the idea that values may be named this way is interesting. We could potentially redefine some of the stack shuffling words this way:

```brief
let 'drop [let '_]
let 'dup [x x let 'x]
let 'swap [y x let 'y let 'x]
let 'over [y x y let 'y let 'x]
let 'pick [z x y z let 'z let 'y let 'x]
```

There are some issues with this around how `let` and application of definitions handle `Lists` vs. other kinds of values. We could `quote` the values to turn `Lists` into definitions that push a `List` literal, but then run into problems with `quote` being defined in terms of `swap`, recursively.

Anyway, we're getting totally side tracked. the real purpose of this feature is to make definitions like this:

```brief
let 'fry [flatmap [if [fill] [deepfry] hole?]
    let 'fill [unless [quote] list? dup rot drop]
    let 'deepfry [if [quote rot 2dip [fry] -rot] [quote] list? dup]
    let 'hole? [= >sym '_ dup]]
```

The three "inner `lets`" are defined and used by the `fry` word exclusively. The remaining problem is that `let`, whether "inner" or not, defines things in a global dictionary. Let's chage the `Dictionary` to a _`List`_ of `Maps`:

```fsharp
and State = {
    Dictionary: Map<string, Value> List
    ... }
```

We'll search this "chain" of dictionary "frames" from head to tail:

```fsharp
let tryFindWord n dict =
    let rec tryFind = function
        | h :: t ->
            match Map.tryFind n h with
            | Some v -> Some v
            | None -> tryFind t
        | [] -> None
    tryFind dict
```

Adding a few more helpers to add and drop words and frames:

```fsharp
let addFrame dict = Map.empty :: dict

let dropFrame = function
    | _ :: [] -> failwith "Cannot drop final dictionary frame"
    | _ :: t -> t
    | [] -> failwith "Malformed dictionary"

let addWord n v = function
    | h :: t -> (Map.add n v h) :: t
    | [] -> failwith "Malformed dictionary"
```

These will be used throughout. Most importantly, the interpreter will now change to add a dictionary frame each time a secondary word is evaluated. Any "inner" `let` will add to _this_ frame. With a tricky bit of mechanics, a `_return` word is then added after the expanded continuation so that, once complete, the new dictionary frame will be dropped. This way, inner `lets` are available only within the parent (or anscestors in general) and don't polute the global dictionary. Also, they may shaddow global words temporarily.

```fsharp
primitive "_return" (fun s -> { s with Dictionary = dropFrame s.Dictionary })

let rec interpret state stream =
    let word state w = 
        match w with
        | Symbol s ->
            match tryFindWord s state.Dictionary with
            | Some (List l) ->
                { state with Dictionary = addFrame state.Dictionary
                             Continuation = List.rev l @ Symbol "_return" :: state.Continuation }
            | Some v -> ...
            | None -> ...
        | v -> ...
    ...
```

Very simple.

In the future, we may want to pre-compile definitions and attach an "environment" to each containing the head dictionary frame. Also, symbols may be resolved at compile-time. This will likely require a bottom-up ordering of definitions and some way of handling mutual recursion.

# 02 JAN 2020 Testing

Before working on some planned refactoring, let's add some facility to add tests.

```brief
let 'assertTrue [clear print fry [_ " " _ "\n"] if ['PASS] ['FAIL] apply swap]
let 'assertFalse [assertTrue dip [compose [not]]]
let 'assertEqual [assertTrue dip [quote =] 2dip [apply]]

let 'test [load 'tests]
```

This allows us to populate a `tests.b` file with unit tests:

```brief
assertEqual "Addition" 7 [+ 4 3]
assertEqual "Subtraction" -1 [- 4 3]
assertEqual "Multiplication" 12 [* 4 3]
assertEqual "Division" 0.5 [/ 4 2]

assertEqual "Reverse" [3 2 1] [reverse [1 2 3]]
assertEqual "Fry" [1 foo [2 bar [baz]]] [fry [_ foo [_ bar _]] 1 2 [[baz]]]

assertEqual "Depth" 3 [depth 1 2 3]
assertEqual "Clear" 0 [depth clear 1 2 3]

assertEqual "Drop" 0 [depth drop 'foo]
assertEqual "Swap" [2 1] [cons dip [cons] swap 1 2 []]
```

# 03 JAN 2020 Exposing Internals

The tests above led to the thinking that the internals could be simplified and exposed directly. For example, the `"Swap"` test:

```brief
assertEqual "Swap" [2 1] [cons dip [cons] swap 1 2 []]
```

It's a bit unwieldy to have to `cons` together a list containing the stack for the test. If we had a means to look at the stack as a value, it could be simplified. Going all the way back to debate #8, this had been an idea on the back burner. Let's remove the `Stack` and add it as a simple value in the `Map`:

```fsharp
let _stack = "_stack"

let emptyState = {
    Continuation = []
    Map = Map.ofList [_stack, List []]
    Dictionary = [Map.empty]
    Primitives = Map.empty }

let getStack state = match Map.tryFind _stack state.Map with Some (List s) -> s | _ -> failwith "Malformed stack"
let setStack state (stack: Value list) = { state with Map = Map.add _stack (List stack) state.Map }
```

That's easy enough to change throughout and now the tests can be rewritten as:

```brief
assertEqual "Swap" [2 1] [@map '_stack swap 1 2]
assertEqual "Dip" [1 6] [@map '_stack dip [*] 1 2 3]
...
```

Additionally, a couple of primitives can now become secondaries:

```brief
let 'clear [!map '_stack []]
let 'depth [nip count @map '_stack]
```

Let's go further and move _everything_ into the `Map`! In fact, the `State` would then _only_ contain the `Map`. Instead, let's define as merely a map (`State = Map<string, Value>`).

```fsharp
let _stack        = "_stack"
let _continuation = "_continuation"
let _dictionary   = "_dictionary"

let emptyState = Map.ofList [
    _stack, List []
    _continuation, List []
    _dictionary, List [Map Map.empty]]
```

To move the `Primitives` to the dictionary, let's promote them to proper `Values` and also bring back our `IComparable` `Primitive` type:

```fsharp
type Value =                        // v
    | Word    of Primitive          // w
    ...
```

The interpreter now handles `Words` by simply applying them to the state (`w.Func state`):

```fsharp
...
match tryFindWord s (getDictionary state) with
| Some (List l) -> ... // expand as continuation
| Some (Word w) -> w.Func state
| Some v -> ... // push to stack
| None -> failwith (sprintf "Unknown word '%s'" s)
```

# 09 JAN 2021 Booleans

Just a small simplification of sorts: Getting rid of the `Boolean` type and replacing with a convention of `-1` meaning `true` and `0` meaning `false`. This unifies boolean and bitwise operations and removes a type from the system, and with slightly more flexible semantics.

```brief
let 'true -1
let 'false 0
```

The `if` word is relaxed to consider _any_ non-zero `Number` to mean `true`. This allows for expressions such as `when [...] count ...` to switch directly on whether the `count` is zero rather than requiring `<> 0 count` or `not empty?`:

```fsharp
 primitive "if" (fun s ->
    match getStack s with
    | List q :: List r :: Number b :: t ->
        (List.rev (if b <> 0.0 then q else r)) @ getContinuation s |> setContinuation (setStack s t)
    ...
```

Boolean operations `and` and `or` change to work with `Numbers`. Interestingly, they become _bitwise_ operations because `-1` is all bits on. This unified the boolean and bitwise operations. Funny that languages like F# have `&&`, `||`, `not` vs. `&&&`, `|||`, `~~~` and languages like C have `&&`, `||`, `!` vs. `&`, `|`, `~`.

```fsharp
let booleanOp name op = primitive name (fun s ->
    match getStack s with
    | Number x :: Number y :: t -> Number (op (int x) (int y) |> double) :: t |> setStack s^M
    ...

booleanOp "and" (&&&)^M
booleanOp "or" (|||)^M

primitive "not" (fun s ->
    match getStack s with
    | Number x :: t -> (Number (~~~(int x) |> double)) :: t |> setStack s^M
    ...
```

Notice that, as boolean operations, these may do the wrong thing if the value is not a "well formed" `-1` or `0`. There is no check for this so that it may equally be used as a bitwise operation; making the language more "dynamic."

Finally, the comparison operations now produce a proper `-1`/`0` value:

```fsharp
 let comparisonOp name op = primitive name (fun s ->
     match getStack s with
     | x :: y :: t -> Number (if (op y x) then -1. else 0.) :: t |> setStack s^M
     ...

comparisonOp "=" (=)
comparisonOp ">" (>)
```

The `>bool` word goes away, and pretty printing no longer shows `true`/`false`; though words for these constants are added for code clarity.

# 10 JAN 2021 Debugging

While changing the semantics of booleans yesterday, a difficult to debug infinite recursion was accidentally caused! In general, we've been avoiding adding features until they're needed. We need a debugger!

Let's change the interpreter to walk step-by-step through the code:

```fsharp
let step state =
    match getContinuation state with
    | Symbol "_return" :: c -> updateDictionary dropFrame state |> setContinuation c
    | Symbol s :: c -> 
        match tryFindWord s state with
        | Some (List l) -> addFrame state |> setContinuation (List.rev l @ Symbol "_return" :: c)
        | Some (Word w) -> setContinuation c state |> w.Func
        | Some v -> pushStack v state |> setContinuation c
        | None -> failwith (sprintf "Unknown word '%s'" s)
    | v :: c -> pushStack v state |> setContinuation c
    | [] -> state

let interpret state code =
    let rec interpret' state =
        match getContinuation state with
        | [] -> state
        | Symbol "_break" :: c -> setContinuation c state
        | _ -> step state |> interpret'
    updateContinuation (fun c -> List.ofSeq code @ c) state |> interpret'
```

Each `step` incrementally advances; expanding a secondary onto the continuation, executing a primitive or pushing a value. One `step`. When we `interpret` a set of `code`, we place it on the continuation and repeatedly `step` until a the end (or a `_break`).

This removes the feature in which a "stream" (`Value seq`) of code would be interpreted _as_ words and values came in. Instead, now we immediately reify the sequence (`List.ofSeq`) and place all of the code on the continuation up front. This is much simpler for debugging and we may revisit streaming later.

This also removes the `_return` primitive and instead it is a "special" internal word, both added and understood in the `step` function.

## Debug Mode

Changing the interpreter again, we add the ability to step in/out/over words. When stepping in, an internal `_pause` word in slipped behind any expanded secondary so that stepping out can be accomplished by stepping until the `_pause` is reached. Stepping over is essentially a step in, then out.

```fsharp
let step into state =
    let pause c = if into then Symbol "_pause" :: c else c
    match getContinuation state with
    | Symbol "_return" :: c -> updateDictionary dropFrame state |> setContinuation c
    | Symbol "_pause" :: c -> setContinuation c state
    | Symbol s :: c -> 
        let c' = pause c
        match tryFindWord s state with
        | Some (List l) -> addFrame state |> setContinuation (List.rev l @ Symbol "_return" :: c')
        | Some (Word w) -> setContinuation c' state |> w.Func
        | Some v -> pushStack v state |> setContinuation c'
        | None -> failwith (sprintf "Unknown word '%s'" s)
    | v :: c -> pushStack v state |> setContinuation (pause c)
    | [] -> state

let rec skip state =
    match getContinuation state with
    | Symbol "_return" :: _
    | Symbol "_pause" :: _ -> step false state |> skip
    | _ -> state

let stepIn state = state |> skip |> step true

let stepOut state =
    let rec out state =
        match getContinuation state with
        | Symbol "_pause" :: _ | [] -> step false state
        | Symbol "_break" :: c -> setContinuation c state
        | _ -> step false state |> out
    out state

let stepOver state = state |> stepIn |> stepOut

let interpret code state =
    let rec interpret' state =
        match getContinuation state with
        | [] -> state
        | Symbol "_break" :: c -> setContinuation c state
        | _ -> step false state |> interpret'
    state |> updateContinuation (fun c -> List.ofSeq code @ c) |> interpret'
```

One interesting thing to notice is that `_pause` marker words are slipped behind even primitives. This allows for stepping into primitives that "expand" the continuation. For example, the `if` and `dip` words. These can be stepped into as well to inspect the quotation being applied.

To invoke these debugging functions, we introduce a new mode in the REPL. Any time the `state` contains a continuation after being `interpreted` we pass off to a `debugger` REPL of sorts which we'll cover momentarily. Notice that `_break` will cause such a thing to happen. So to enter the debugger, we just "set a break point"; typing `break` wherever we want at the REPL or in `loaded` code.  We can now set "break into the debugger" with `_break`! Pressing ENTER at the REPL will continue interpreting after breaking. We define a less internal-looking word `break` (sans underscore) to be used in code (`let 'break [_break]`). This can be overridden to disable or make conditional breakpoints.

```fsharp
and repl state =
    if getContinuation state |> List.length > 0
    then debugger state else
        printPrompt false state
        try
            match Console.ReadLine() with
            | "exit" -> ()
            | line -> state |> (line |> brief |> interpret) |> repl
        with ex -> printfn "Error: %s" ex.Message; repl state
```

The `debugger` "REPL" doesn't allow typing lines of code. Instead control keys drive the interaction. Pressing `Enter` will continue interpretation and return to the regular REPL (unless a `_break` is hit!). Pressing `RightArrow` will step over, `DownArray` will step in and `UpArrow` will step out. Whenever the continuation is exhausted, it returns to the regular REPL.

```fsharp
let rec debugger state =
    if getContinuation state |> List.length = 0
    then repl state else
        try
            printPrompt true state
            let key = Console.ReadKey()
            match key.Key with
            | ConsoleKey.Enter -> interpret [] state |> repl
            | ConsoleKey.RightArrow -> stepOver state |> debugger
            | ConsoleKey.DownArrow -> stepIn state |> debugger
            | ConsoleKey.UpArrow -> stepOut state |> debugger
            | _ -> debugger state
        with ex -> printfn "Error: %s" ex.Message; state |> setContinuation [] |> repl
```

Finally, a bit of "visualization" shows the continuation (in dark gray) followed by the stack (in white), separated by a pipe (`|`) that's either blue in regular mode or red in debug mode.

```fsharp
let printPrompt debugging s =
    let continuation = getContinuation s |> List.rev |> stringOfValues
    let stack = stringOfValues (getStack s)
    Console.ForegroundColor <- ConsoleColor.DarkGray
    Console.Write(continuation)
    Console.ForegroundColor <- if debugging then ConsoleColor.DarkRed else ConsoleColor.DarkBlue
    Console.Write(" | ")
    Console.ForegroundColor <- ConsoleColor.White
    Console.WriteLine(stack)
```

This all seems to work beautifully!

```brief
area break 7.2
      area | 7.2
   * pi sq | 7.2
* pi * dup | 7.2
    * pi * | 7.2 7.2
      * pi | 51.84
         * | 3.14159 51.84
           | 162.86
```

# 16 JAN 2021 Brief in Brief

Let's start writing Brief in Brief itself. Starting with the lexer and then the parser.

First though, a very useful word to add the prelude is `cond`:

```brief
let 'cond [if [drop] [if [apply head] [pair] = 1 count] empty?
    let 'pair [if [apply nip] [cond drop] rot dip [dip snoc] snoc]]
```

This walks a list of quotations, applying the first if the second yields true, the third if the fourth yields true, etc. with an optional final default. For example:

```brief
cond [[<do this when...>] [<...this is true>]
      [<or this when...>] [<...this is true>]
      [<or this otherwise]]
```

The lexer tokenizes a string of text; breaking on whitespace (except for strings in quotes). We normally treat brackets as tokens (except when escaped), etc. but this is getting confusing and complicated. For example, `[ ']]` or `[']`. Thes first is a list containing a `"]"` string, while the second is a list contining an empty string. But, opps, `']` is a string containing the right square bracket! Okay, fine, so we escape brackets in ticked strings: `['\]]` vs. `[']`. Much too complicated. Lets just go back to white space separated tokens; including brackets. Factor does this. Trying to be like Joy is leading to a complicated parser, and writing this correctly in Brief is overcomplicating things.

```brief
let 'whitespace? [ any? swap [ " " '\r '\n '\t ] fry [ = _ ] dup ]

let 'lex [ tokenize rot [ ] [ ] split
    let 'tokenize [ cond [ [ done ]                [ empty? ]
                           [ tokenize token drop ] [ whitespace? snoc ]
                           [ tick addChar ]        [ firstCharIs? '' ]
                           [ str addChar '' drop ] [ firstCharIs? '" ]
                           [ tokenize addChar ] ]
        let 'firstCharIs? [ apply fry [ and dip [ = _ dup ] rot 2dip [ empty? ] ] ] ]
    let 'str [ cond [ [ tokenize token drop ]  [ = '" dup snoc ]
                      [ str addChar unescape ] [ = '\\ dup ]
                      [ str addChar ] ] ]
    let 'tick [ cond [ [ done ]                  [ empty? ]
                       [ tokenize token drop ]   [ whitespace? snoc ]
                       [ tick addChar unescape ] [ = '\\ dup ]
                       [ tick addChar ] ] ]
    let 'unescape [ cond [ [ '\b drop ] [ = 'b dup ]
                           [ '\f drop ] [ = 'f dup ]
                           [ '\n drop ] [ = 'n dup ]
                           [ '\r drop ] [ = 'r dup ]
                           [ '\t drop ] [ = 't dup ] ] snoc drop ]
    let 'done [ 2drop token ]
    let 'addChar [ dip [ cons ] swap ]
    let 'emptyToken? [ swap dip [ empty? ] ]
    let 'singleCharToken [ token dip [ cons ] swap dip [ token ] ]
    let 'token [ swap [  ] if [ drop ] [ dip [ cons ] swap join reverse ] empty? swap ] ]

```

For example, `lex "this [ is { a } ] test"` -> `['test '\] '\} 'a '\{ 'is '\[ 'this]`. Brackets and simple tokens are broken on whitespace. Another example, `lex "this \"foo is a\" test"` -> `['test "'foo is a" 'this]`. Regular strings become a sinple token (notice, with a leading tick).

The parser then assembles this flat list of tokens into a list of structured values. Strings remain as such, but symbols and numbers are converted. Nested brackets and braces are built into lists and maps.

```brief
let 'parse [ next swap [  ]
    let 'next [ cond [ [ drop ]                         [ empty? ]
                       [ next dip [ cons ] parse drop ] [ = "]" dup snoc ]
                       [ drop ]                         [ or bi [ = "{" ] [ = "[" ] dup ]
                       [ next buildMap parse drop ]     [ = "}" dup ]
                       [ next dip [ cons convert ] swap ] ] ] ]
    let 'convert [ cond [ [ join tail split ] [ = '' head split dup ]
                          [ nip ]             [ >num? dup ]
                          [ >sym ] ] ]
    let 'buildMap [ build rot { } ]
        let 'build [ if [ dip [ cons ] swap drop ]
                       [ build dip [ ! swap ] swap snoc swap snoc ] empty? ]
```

Writting this code was a pretty fun exercise in using Brief 'in anger." It's nice to see also that it ends up more "brief" than the F#.

However, we still need the F# version of the lexer and parser, to lex and parse the new lexer and parser! Solving this will be the next adventure.

Next we add `lex` and `parse` as primitive words that are then redefined in Brief as above.

```fsharp
primitive "lex" (fun s ->
    match getStack s with
    | String b :: t -> setStack ((lex b |> Seq.map String |> List.ofSeq |> List) :: t) s
    | _  :: _ -> failwith "Expected s"
    | _ -> failwith "Stack underflow")

primitive "parse" (fun s ->
    let toString = function String s -> s | _ -> failwith "Expected String"
    match getStack s with
    | List l :: t -> setStack ((l |> Seq.map toString |> parse |> compile |> Seq.rev |> List.ofSeq |> List) :: t) s
    | _  :: _ -> failwith "Expected l"
    | _ -> failwith "Stack underflow")
```

Other words are defined in terms of these. For example, `load` goes away and a new `read` word is added to load the contents of source files. The `load` word then reads, lexes, parses and applies: `let 'load [ apply parse lex readText ]`. Initially this didn't work, by the way because definitions were being made in the secondary dictionary frame. The interpreter was changed to only add/remove dictionary frames when the secondary contains a `let`. This will need to be revised.

DEBATE 23: Revisit dictionary frames. Definitions should be added _once_ and maintained in an environment attached to the secondary. Possibly...

# 17 JAN 2021 State Persistence

Mainly to enable loading of definitions, let's add serialization of Values. A nice, uniform binary format will be easily parsed.

```fsharp
let rec serialize (writer: BinaryWriter) = function
    | Symbol s -> writer.Write(0uy); writer.Write(s)
    | String s -> writer.Write(1uy); writer.Write(s)
    | Number n -> writer.Write(2uy); writer.Write(n)
    | List l -> writer.Write(3uy); writer.Write(l.Length); List.iter (serialize writer) l
    | Map m ->
        writer.Write(4uy); writer.Write(m.Count)
        Map.iter (fun (k: string) v -> writer.Write(k); serialize writer v) m
    | Word w -> writer.Write(5uy); writer.Write(w.Name)
```

It doesn't get much simpler than this. A single-byte type tag prefixes values. Strings and symbols are length-prefixed, UTF-8 encoded bytes. Numbers are IEEE754 four-byte doubles. Lists are length-prefixed sets of Values. Maps are also length-prefixed sets of pairs of string and Value. Finally, Words are merely the primitive's name and are expected to be mapped to known `(State -> State)` functions when deserialized.

Deserialization is extreemely simple:

```fsharp
let rec deserialize primitives (reader: BinaryReader) =
    match reader.ReadByte() with
    | 0uy -> reader.ReadString() |> Symbol
    | 1uy -> reader.ReadString() |> String
    | 2uy -> reader.ReadDouble() |> Number
    | 3uy -> List.init (reader.ReadInt32()) (fun _ -> deserialize primitives reader) |> List
    | 4uy -> Seq.init (reader.ReadInt32()) (fun _ -> reader.ReadString(), deserialize primitives reader) |> Map.ofSeq |> Map
    | 5uy -> let n = reader.ReadString() in match Map.tryFind n primitives with Some (Word w) -> Word w | _ -> sprintf "Unknown primitive: %s" n |> failwith
    | _ -> failwith "Unknown type tag"
```

Next, we add words to `save` and `open` what we'll call "image" files persisting the whole machine state; complete with stack, continuation and more importantly the dictionary of secondary (and primitive) definitions:

```fsharp
primitive "save" (fun s ->
    match getStack s with
    | String n :: t ->
        let s' = setStack t s
        use writer = new BinaryWriter(File.OpenWrite(sprintf "%s.i" n))
        serialize writer (Map s')
        s'
    | _ :: _ -> failwith "Expected s"
    | _ -> failwith "Stack underflow")

primitive "open" (fun s ->
    match getStack s with
    | String n :: t ->
        let s' = setStack t s
        let primMap = primitives |> Seq.map (fun p -> p.Name, Word p) |> Map.ofSeq
        use reader = new BinaryReader(File.OpenRead(sprintf "%s.i" n))
        match deserialize primMap reader with
        | Map m -> m
        | _ -> failwith "Invalid image"
    | _ :: _ -> failwith "Expected s"
    | _ -> failwith "Stack underflow")
```

So now the `prelude.b` is loaded on startup (with `if parse lex read 'prelude.b [ ] -1` because `load` and even `apply` have yet to be defined). Then we can `load 'brief.b` to redefine `lex` and `parse` in Brief itself. Then we can `save 'boot.i`.

Now for the finale, we can restart the REPL _without_ loading the `prelude.b` and without loading `brief.b` (and even perhaps commenting out the F# implementation of `lex` and `parse`) and then `open 'boot.i` to get back all the definitions; including our new Brief-based lexer and parser. From there we can `load 'someRandomSource.b` (or `brief.b` itself!) and we're off to the races!

Well, a very sloooow race at least. It's *quite* slow. Working on performance may come next.

# 30 JAN 2021 Performance

The current performance is abysmal! Loading the Brief-based lexer/parser (`load 'brief.b`) and running the tests (`test`) takes *minutes*! Why? It normally takes a fraction of a second.

To figure this out, let's add a few words to help performance test things:

| Word | Stack | Description | Type |
| --- | --- | --- | --- |
| `stopwatch-reset` | - | Reset and start stopwatch. | Primitive |
| `stopwatch-elapsed` | n | Return elapsed milliseconds. | Primitive |
| `time` | q-n | Apply quotation while running stopwatch; returning elapsed milliseconds. | Secondary |
| `steps-reset` | - | Reset interpreter step count. | Primitive |
| `steps-count` | n | Return current interpreter step count. | Primitive |
| `steps` | q-n | Apply quotation while returning counted steps. | Secondary |
| `perf` | q-nn | Apply quotation while running stopwatch; returning counted steps and elapsed milliseconds. | Secondary |

Timing tests can easily be done now with `time [ test ]`. The `time` word simply applies a quotation while timing it. The `steps` word is similar but counts interpretation steps. The `perf` word does both.

```brief
let 'time [ stopwatch-elapsed apply stopwatch-reset ]
let 'steps [ steps-count apply steps-reset ]
let 'perf [ steps-count stopwatch-elapsed apply stopwatch-reset steps-reset ]
```

It seems that indeed the F#-based `lex`/`parse` primitives can be used to load and run tests in ~329ms, while the Brief-based reimplementations take a whopping ~233439ms (almost 4 minutes!). Not sane.

A suspicion is that it's the nested `lets` and re-evaluation of those; especially within recursive words. Running perf tests while flattening some of the words shows some promise. Suddenly, flattening `cond` makes a *huge* difference. For example, changing from:

```brief
let 'cond [ if [ drop ] [ if [ apply head ] [ pair ] = 1 count ] empty?
    let 'pair [ if [ apply nip ] [ cond drop ] rot dip [ dip snoc ] snoc ] ]
```

To a "flat" version by changing `pair` to `cond.pair` as a "namespace" (while still indenting for style) and most importantly removing it from inside the definition of `cond` (merely moving the trailing bracked ']' up a line):

```brief
let 'cond [ if [ drop ] [ if [ apply head ] [ cond.pair ] = 1 count ] empty? ]
    let 'cond.pair [ if [ apply nip ] [ cond drop ] rot dip [ dip snoc ] snoc ]
```

Now the tests complete in ~4265ms (just over 4 seconds instead of just under 4 *minutes*).

Adding some instrumentation to the F# code, we notice that the chain of dictionaries is insanely long! The list grows up to 5340! The total dictionary lookups, including walking and searching each dictionary in the chain is an incredible 8,144,500,000 (eight *billion*). This is the main performance problem; caused by recursive words with inner `lets` building an ever-increasing chain of dictionaries.

Still thinking about how to deal with this long-term, but for now let's just keep the Brief code flattened and get rid of the idea of dictionary frames entirely. Get rid of the `_return` mechanism, and simplify dictionary updates and lookup. Now the `_dictionary` within the state is a simple, single `Map` instead of a `List` of `Maps`.

The result is that the F# lexer/parser is still *much* quicker and, of course, involves far fewer Brief steps (29,103 steps in 329ms). The Brief-based lexer/parser takes 4,838,500 steps and 3169ms. That's somewhat reasonable. ~10x slower, but livable. There's still quite a bit that could be done to improve performance with pre-"compiling" of secondaries into already resolved children or even reducing (when possible e.g. no recursive) into threads of pure primitives.

# [OCT 2021](https://github.com/AshleyF/brief/blob/gh-pages/sandbox/Language/journal/OCT2021.md)